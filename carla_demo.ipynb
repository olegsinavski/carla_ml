{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4d1a6-c924-4143-8a52-a37d4c170add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import carla\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(2.0)\n",
    "assert client.get_client_version() == client.get_server_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c1027-3461-4e64-ba9b-008054931f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(client.get_server_version())\n",
    "\n",
    "print(dir(client))\n",
    "print(client.get_world())\n",
    "print(client.get_available_maps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818650c4-a9ab-45d9-b56b-323c65ee7218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "client.set_timeout(60.0)\n",
    "world = client.load_world('Town02')\n",
    "client.set_timeout(2.0)\n",
    "print(client.get_world())\n",
    "settings = world.get_settings()\n",
    "settings.fixed_delta_secodnds = 0.05 #must be less than 0.1, or else physics will be noisy\n",
    "#must use fixed delta seconds and synchronous mode for python api controlled sim, or else \n",
    "#camera and sensor data may not match simulation properly and will be noisy \n",
    "settings.synchronous_mode = True \n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f54f71-8a5f-48ef-975f-bd6cdd89b36c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "actor_list = []\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "bp = random.choice(blueprint_library.filter('vehicle')) # lets choose a vehicle at random\n",
    "\n",
    "# lets choose a random spawn point\n",
    "transform = random.choice(world.get_map().get_spawn_points()) \n",
    "\n",
    "#spawn a vehicle\n",
    "vehicle = world.spawn_actor(bp, transform) \n",
    "actor_list.append(vehicle)\n",
    "\n",
    "vehicle.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b2cba-4277-4d8d-8425-edc72cb3ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create waypoints for driving the vehicle around automatically\n",
    "m= world.get_map()\n",
    "waypoint = m.get_waypoint(transform.location)\n",
    "\n",
    "#lets add more vehicles\n",
    "for _ in range(0, 10):\n",
    "    transform = random.choice(m.get_spawn_points())\n",
    "\n",
    "    bp_vehicle = random.choice(blueprint_library.filter('vehicle'))\n",
    "\n",
    "    # This time we are using try_spawn_actor. If the spot is already\n",
    "    # occupied by another object, the function will return None.\n",
    "    other_vehicle = world.try_spawn_actor(bp_vehicle, transform)\n",
    "    if other_vehicle is not None:\n",
    "        print(npc)\n",
    "        other_vehicle.set_autopilot(True)\n",
    "        actor_list.append(other_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300755a7-fe3e-4b67-ac88-6637fda2da7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "#example for getting camera image\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)\n",
    "actor_list.append(camera)\n",
    "\n",
    "#example for getting depth camera image\n",
    "camera_depth = blueprint_library.find('sensor.camera.depth')\n",
    "camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera_d = world.spawn_actor(camera_depth, camera_transform, attach_to=vehicle)\n",
    "image_queue_depth = queue.Queue()\n",
    "camera_d.listen(image_queue_depth.put)\n",
    "actor_list.append(camera_d)\n",
    "\n",
    "#example for getting semantic segmentation camera image\n",
    "camera_semseg = blueprint_library.find('sensor.camera.semantic_segmentation')\n",
    "camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera_seg = world.spawn_actor(camera_semseg, camera_transform, attach_to=vehicle)\n",
    "image_queue_seg = queue.Queue()\n",
    "camera_seg.listen(image_queue_seg.put)\n",
    "actor_list.append(camera_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aad5db-87e8-4b5e-ac6d-6934f584405f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def get_mask(seg_im, rgb_value):\n",
    "    # rgb_value should be somethiing like np.uint8([[[70, 70, 70]]])\n",
    "    # seg_im should be in HSV\n",
    "    \n",
    "    hsv_value = cv2.cvtColor(rgb_value, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    hsv_low = np.array([[[hsv_value[0][0][0]-5, hsv_value[0][0][1], hsv_value[0][0][2]-5]]])\n",
    "    hsv_high = np.array([[[hsv_value[0][0][0]+5, hsv_value[0][0][1], hsv_value[0][0][2]+5]]])\n",
    "    \n",
    "    mask = cv2.inRange(seg_im, hsv_low, hsv_high)\n",
    "    return mask\n",
    "\n",
    "def get_bbox_from_mask(mask):\n",
    "    label_mask = measure.label(mask)\n",
    "    props = measure.regionprops(label_mask)\n",
    "    \n",
    "    return [prop.bbox for prop in props]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5740bf-8ff3-4dfa-adb2-a39ba774ff96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae2dd5-a8ae-4efb-8990-49fdc5326e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rgb camera\n",
    "image = image_queue.get()\n",
    "\n",
    "#semantic segmentation camera\n",
    "image_seg  = image_queue_seg.get()\n",
    "\n",
    "#depth camera\n",
    "image_depth = image_queue_depth.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca9850-fc1f-43ab-8359-459205f45683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def carla_image_to_pil(carla_image):\n",
    "    # Check if the input is a CARLA image\n",
    "    if not isinstance(carla_image, carla.Image):\n",
    "        raise ValueError(\"Input must be a CARLA Image.\")\n",
    "\n",
    "    # Get the image dimensions and format\n",
    "    width, height = carla_image.width, carla_image.height\n",
    "    # Convert the CARLA image to a numpy array\n",
    "    array = np.frombuffer(carla_image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (height, width, 4))\n",
    "    array = array[:, :, (2, 1, 0)]\n",
    "    return Image.fromarray(array, \"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49cdc2-976a-4913-a128-69be3b177a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(carla_image_to_pil(image))\n",
    "display(carla_image_to_pil(image_seg))\n",
    "display(carla_image_to_pil(image_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984adb78-aa57-433f-9d89-83e922175dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "keyboard_input = widgets.Text()\n",
    "\n",
    "def handle_keypress(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        last_key_pressed = change['new'][-1] if change['new'] else ''\n",
    "        print(f\"Key pressed: {last_key_pressed}\")\n",
    "        keyboard_input.value = ''\n",
    "\n",
    "keyboard_input.observe(handle_keypress)\n",
    "display(keyboard_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003dda1-25e8-47a3-a8b8-458deff17ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pygame\n",
    "import sys\n",
    "# Set up the screen (window) to capture events\n",
    "screen = pygame.display.set_mode((400, 300))\n",
    "\n",
    "print('hello')\n",
    "# Game loop\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "        \n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            print(f\"Key pressed: {event.key} ({pygame.key.name(event.key)})\")\n",
    "            world.tick()\n",
    "\n",
    "    # Update the display\n",
    "    pygame.display.flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc24683-167f-477e-8a9b-019d9e79d196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
